# AI & ML

## Singularity & Cyborgs
- [Ray Kurzweil](https://www.goodreads.com/book/show/83518.The_Singularity_is_Near)
- [Donna Haraway](https://en.wikipedia.org/wiki/A_Cyborg_Manifesto)

## Uncanny Valley
- Robots: OK, Humans: OK. Can't tell? Not OK
- [Cats (2019)](https://www.youtube.com/watch?v=FtSd844cI7U)
- [AIVA](https://www.youtube.com/watch?v=6I3aKYyKl68)
- [Turing Test](http://web.cse.ohio-state.edu/~stiff.4/cse3521/turing-test.html)
- Bots
- [Google Translate](https://translate.google.com/)
- Much is made of them, but the Singularity, the Uncanny Valley and the concept of "Smart" are **socially-constructed**

## "AI" vs "Machine Learning" according to AI folks
- "Science of Making Machines Smart" - Demis Hassabis (Google DeepMind)
- Make a machine do something 'smart,' automatically adapt to users, provide them unique experience
- Early methods include **Logic or Expert Systems**
  - Creator 'solves' problem
  - [DeepBlue](https://en.wikipedia.org/wiki/Deep_Blue_(chess_computer))
  - Can't deal with the unexpected, can't learn anything new
- Machine Learning
  - Machine can learn new things
  - [AlphaGo](https://en.wikipedia.org/wiki/AlphaGo)
  - [BINA48](https://www.hansonrobotics.com/bina48-9/)
  - [chatGPT-3](https://www.nytimes.com/2022/04/15/magazine/ai-language.html?searchResultPosition=2)
  - but can it learn **beyond its training data**?

### Types of Machine Learning
- Supervised (training data has all the answers)
- Unsupervised (anomaly detection)
- Semisupervised (partially labelled, looking for patterns)
- Reinforcement learning (getting towards AI...like training a dog with positive and negative rewards)

### Modes
- Batch learning (you get all the training data at once)
- "Online" learning (system can accept new training data on the go)
- Instance-based (commits training data to memory, then compares new data to training data)
- Model-based (generalizes from a set of examples then uses that model to make predictions)

### Problems...
- Insufficient quantity of training data
- Poor quality of training data
- Non-representative training data
- Transparent Data Gathering Practices?
- Transparent Training Practices?
- Transparent Model Distribution?

### Large Language Models 
- chatGPT (openAI...Microsoft), llama (META), Gemini (Google)
- 'Generative AI'

### [Artificial General Intelligence](https://en.wikipedia.org/wiki/Artificial_general_intelligence)
- Neural Networks
  - identifies + reproduces patterns in the same way a human brain does
  - used to be called "deep learning"
- *what can it learn beyond it's training data?*
- [Agentic AI](https://blogs.nvidia.com/blog/what-is-agentic-ai/)



**Art**
- [Stephanie Dinkins: Conversations with BINA48](https://www.stephaniedinkins.com/conversations-with-bina48.html)
- [Daniel Ek, Spotify and AI](https://www.vice.com/en/article/epxxkn/musicians-are-dragging-spotifys-ceo-for-funding-a-military-ai-company)
- [My Favorite Deep Fake](https://moondisaster.org/film)
- ["Your" Favorite Deep Fake](https://www.youtube.com/watch?v=VWrhRBb-1Ig)
